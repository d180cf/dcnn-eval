The idea is to build a DCNN that would answer one question:
is the group safe? More precisely, it will tell whether
the group cannot be captured if the opponent starts
and can recapture any ko. If the group is safe, the player
can tenuki. If it's not safe, a move is needed to protect it.

# Features

The input to the DCNN will be a list of planes with features
or in other terms in will be a tensor of shape `[N, N, F]`
where `F` is the number of features and `N x N` is the area
that these features are computed for. A reasonable choice would
be `11 x 11` or `9 x 9` because most tsumegos fit in this area.

The features are:

- location is outside the board
- stone is black
- stone is white
- stone is in atari, i.e. it has only 1 liberty
- stone has adjcent stones of the same color

More features to be implemented:

- stone can be captured in a ladder (aka the lambda-1 sequence)
- stone can be captured with a net (aka the lambda-2 sequence)
- location is the center of a nakade shape
- safe group, i.e. stone belongs to the outer wall or to an alive shape
- some sort of eye-detection, heuristics and so on

# DCNN

This set of feature tensors is fed to a Python script that
uses TensorFlow to find the DCNN parameters.

Once the DCNN parameters are found, it can be used in the tsumego
solver to evaluate the board and refine the search.

For now the DCNN design is simple and is taken from the ["MNIST for Experts"](https://www.tensorflow.org/get_started/mnist/pros) TensorFlow tutorial:

1. The input is a set of `[11, 11, 5]` tensors where `11 x 11` is an area on the board with the target stone in the center and `5` is the number of features described above.
2. The 1-st layer transofrms this tensor into a let's say `[5, 5, 10]` one with a convolution and max pooling. The area is shirnked to `5 x 5`, but the number of features is doubled.
3. The 2-nd layer does the same and makes a `[2, 2, 20]` tensor.
4. Densely-connected layer transforms the `[2, 2, 20]` tensor into a `[256]` vector.
5. Dropout to reduce overfitting.
6. Readout to transform the `[256]` vector into a value in the `0..1` range: the prediction whether the target group is safe.

# How inputs to DCNN are generated

There is a set of 100 or so handmade (well, mostly taken from goproblems.com) tsumegos with proper outer wall and marked target. They are stored in the `sgf-problems` module.

```
npm run solve-all
```

Solves each tsumego and outputs a tree of subproblems. When generating the tree the script picks moves that change the safety status of the target group. Every node (not just leafs) in this tree is a subproblem. This step takes a while, but its output is compact, so results can be saved as a npm package.

```
npm run vplay-all
```

Plays out all the moves in the tree and generates a separate SGF file for each node. Each subproblem is labeled with `TS[1]` if the target group is safe. This step doesn't take long, but the output is huge: about 0.5M SGF files.

```
npm run check-all
```

Can verify the `TS[1]` labels. It picks a small percentage of SGF files, solves them and checks if the status is correct. This step is optional.

```
npm run feats-all
```

Computes features for all subproblems. It outputs a JSON file with feature planes and a JSON file with description for each subproblem. The feature planes are tensors of variable shape: `[N, N, F]` where `N` is the board size and `F` is the number of features.

```
npm run ???
```

From each JSON file with features a script takes `N x N` areas around a stone in the target block. The result is a feature tensor of known shape: `[N, N, F]` where `N` is the chosen size of the sliding window (9 or 11 would be a reasonable choice because most problems fit into a smaller area). There are also 8 symmetries generated by rotation and transposition. This step effectively multiplies the number of subproblems by the average number of stones in the target block and then by 8.

```
npm run ???
```

Finally the set of feature tensors with labels is converted to a TensorFlow format and is fed to the Python script that trains DCNN.
